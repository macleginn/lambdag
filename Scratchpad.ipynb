{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "05ac5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm.auto import tqdm\n",
    "from pos_noise import POSNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/dniko/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /home/dniko/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to /home/dniko/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /home/dniko/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to /home/dniko/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /home/dniko/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('reuters')\n",
    "nltk.download('webtext')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1da4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_noise = POSNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ab7996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sentences = (\n",
    "    list(nltk.corpus.brown.sents()) +\n",
    "    list(nltk.corpus.gutenberg.sents()) +\n",
    "    list(nltk.corpus.reuters.sents()) +\n",
    "    list(nltk.corpus.webtext.sents()) +\n",
    "    [post.text for post in nltk.corpus.nps_chat.xml_posts()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b4ce196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246908, 6132220)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reference_sentences), sum(len(s) for s in reference_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a128a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow without multiprocessing\n",
    "# brown_pos_noised = list(map(pos_noise.apply_noise, brown_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010d5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    \"\"\"\n",
    "    A wrapper function for a parallel loop.\n",
    "    \"\"\"\n",
    "    return pos_noise.apply_noise(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b1b90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_processes = mp.cpu_count() - 2\n",
    "num_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d101596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 246908/246908 [05:09<00:00, 797.06it/s] \n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=num_processes) as pool:\n",
    "    pos_noised_sentences = list(tqdm(\n",
    "        pool.imap_unordered(process_sentence, reference_sentences),\n",
    "        total=len(reference_sentences),\n",
    "        desc=\"Processing\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e1e48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('NOUN', 1106025),\n",
       "  ('VERB', 375756),\n",
       "  (',', 329776),\n",
       "  ('PROPN', 297994),\n",
       "  ('ADJ', 292420),\n",
       "  ('the', 281399),\n",
       "  ('NUM', 251938),\n",
       "  ('.', 236402),\n",
       "  ('and', 154816),\n",
       "  ('of', 147851)],\n",
       " [('astraddle', 1),\n",
       "  ('tho', 1),\n",
       "  ('differing', 1),\n",
       "  ('condition', 1),\n",
       "  ('mind', 1),\n",
       "  (\"'(\", 1),\n",
       "  ('-.', 1),\n",
       "  ('foreground', 1),\n",
       "  ('firstly', 1),\n",
       "  ('+,', 1)],\n",
       " 817)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts = Counter()\n",
    "for result in pos_noised_sentences:\n",
    "    pos_counts.update(result)\n",
    "pos_stats = pos_counts.most_common()\n",
    "pos_stats[:10], pos_stats[-10:], len(pos_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e5f95ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/reference_corpus_w_pos_noise.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add the JSON as a file in the archive\n",
    "    zipf.writestr('reference_corpus_w_pos_noise.json', json.dumps(pos_noised_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "375d1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.lm import WittenBellInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "389c2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngram_model(sentences, n=3, vocab=None):\n",
    "    \"\"\"\n",
    "    Train an n-gram model on the given sentences.\n",
    "    \"\"\"\n",
    "    train, vocab_local = padded_everygram_pipeline(n, sentences)\n",
    "    if vocab is None:\n",
    "        vocab = vocab_local\n",
    "    model = WittenBellInterpolated(order=n, vocabulary=vocab)\n",
    "    # model = KneserNeyInterpolated(n, discount=0.75)\n",
    "    model.fit(train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8c6bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_prob(model, sentence):\n",
    "    \"\"\"\n",
    "    Get the log probability of a sentence using the trained model.\n",
    "    \"\"\"\n",
    "    n = model.order\n",
    "    padded_sentence = ['<s>'] * (n - 1) + sentence + ['</s>']\n",
    "    log_prob = 0.0\n",
    "    for i, word in enumerate(padded_sentence):\n",
    "        if i < n - 1:\n",
    "            continue\n",
    "        context = tuple(padded_sentence[i - n + 1:i])\n",
    "        word = padded_sentence[i]\n",
    "        log_prob += np.log(model.score(word, context) + 1e-10)\n",
    "    return log_prob / len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b6dd1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "SAMPLE_SIZE = 10000\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "714a270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "\n",
    "# Filter by frequency if needed\n",
    "filtered_words = {word for word, count in pos_counts.items() if count >= min_freq}\n",
    "\n",
    "# Add special tokens\n",
    "filtered_words.add('<s>')\n",
    "filtered_words.add('</s>')\n",
    "filtered_words.add('<UNK>')\n",
    "\n",
    "# Create the NLTK Vocabulary from this set\n",
    "full_vocab = Vocabulary(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b57878b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:23<00:00,  7.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train N n-gram models on random subsets of the reference corpus\n",
    "grammars = []\n",
    "for i in tqdm(range(N)):\n",
    "    sampled_sentences = random.sample(pos_noised_sentences, SAMPLE_SIZE)\n",
    "    model = train_ngram_model(sampled_sentences, n=n, vocab=full_vocab)\n",
    "    grammars.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7164f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"For that reason, we decided to postpone the meeting until next week.\",\n",
    "    \"Whatever you decide, I will support your choice.\",\n",
    "    \"I'll be ready to leave in a moment.\",\n",
    "    \"She used to live in Paris before moving to London.\",\n",
    "    \"All in all, it was a successful event despite the minor issues.\",\n",
    "    \"He doesn't like coffee, so he always drinks tea.\",\n",
    "    \"In addition to her job, she volunteers at the local shelter.\",\n",
    "    \"They discussed the project at length during the meeting.\",\n",
    "    \"In any event, we should be prepared for any outcome.\",\n",
    "    \"She enjoys hiking as well as that she loves swimming.\",\n",
    "    \"In addition, we need to consider the budget constraints.\",\n",
    "    \"You should take care of yourselves during the trip.\",\n",
    "    \"I'd like to visit the museum this weekend.\",\n",
    "    \"Please stand at the front of the line.\",\n",
    "    \"For one thing, we need more time to complete the project.\",\n",
    "    \"You will receive the results in due time.\",\n",
    "    \"To summarize, the main points are clear and concise.\",\n",
    "    \"Who is responsible for this task?\",\n",
    "    \"The contract specifies the terms wherein the agreement can be terminated.\",\n",
    "    \"Her painting style is similar to that of the famous artist.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1626aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For that reason, we decided to postpone the meeting until next week.\n",
      "\t-5.50, -5.10, -4.71\n",
      "Whatever you decide, I will support your choice.\n",
      "\t-4.48, -4.04, -3.60\n",
      "I'll be ready to leave in a moment.\n",
      "\t-6.25, -5.40, -4.56\n",
      "She used to live in Paris before moving to London.\n",
      "\t-5.63, -5.24, -4.84\n",
      "All in all, it was a successful event despite the minor issues.\n",
      "\t-3.95, -3.54, -3.13\n",
      "He doesn't like coffee, so he always drinks tea.\n",
      "\t-5.51, -5.07, -4.64\n",
      "In addition to her job, she volunteers at the local shelter.\n",
      "\t-3.04, -2.86, -2.67\n",
      "They discussed the project at length during the meeting.\n",
      "\t-3.99, -3.68, -3.37\n",
      "In any event, we should be prepared for any outcome.\n",
      "\t-5.62, -4.76, -3.90\n",
      "She enjoys hiking as well as that she loves swimming.\n",
      "\t-4.45, -4.20, -3.96\n",
      "In addition, we need to consider the budget constraints.\n",
      "\t-2.92, -2.84, -2.76\n",
      "You should take care of yourselves during the trip.\n",
      "\t-5.51, -5.15, -4.79\n",
      "I'd like to visit the museum this weekend.\n",
      "\t-5.34, -4.51, -3.67\n",
      "Please stand at the front of the line.\n",
      "\t-4.73, -4.30, -3.86\n",
      "For one thing, we need more time to complete the project.\n",
      "\t-4.57, -3.74, -2.90\n",
      "You will receive the results in due time.\n",
      "\t-5.09, -4.32, -3.54\n",
      "To summarize, the main points are clear and concise.\n",
      "\t-4.57, -4.10, -3.63\n",
      "Who is responsible for this task?\n",
      "\t-4.36, -4.11, -3.86\n",
      "The contract specifies the terms wherein the agreement can be terminated.\n",
      "\t-3.23, -2.95, -2.67\n",
      "Her painting style is similar to that of the famous artist.\n",
      "\t-5.07, -4.48, -3.90\n"
     ]
    }
   ],
   "source": [
    "for s in test_sentences:\n",
    "    log_probs = np.zeros(len(test_sentences))\n",
    "    s_w_pos_noise = pos_noise.apply_noise(s)\n",
    "    print(s, end='\\n\\t')\n",
    "    for i, model in tqdm(enumerate(grammars), total=len(grammars), leave=False, disable=True):\n",
    "        log_probs[i] = get_log_prob(model, s_w_pos_noise)\n",
    "    std = np.std(log_probs)\n",
    "    mean = np.mean(log_probs)\n",
    "    print(f'{mean - std:.2f}, {mean:.2f}, {mean + std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc5e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
